---
title: "Take-home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods"
execute: 
  warning: false
  message: false
editor: visual
---

## The Task

The specific tasks of this take-home exercise are as follows:

-   Using appropriate **sf** method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. We can use any one of them.

-   Using appropriate **tidyr** and **dplyr** methods, derive the proportion of functional and non-functional water point at LGA level (i.e. ADM2).

-   Combining the geospatial and aspatial data frame into simple feature data frame.

-   Delineating water point measures functional regions by using conventional hierarchical clustering.

-   Delineating water point measures functional regions by using spatially constrained clustering algorithms.

### Thematic Mapping

-   Plot to show the water points measures derived by using appropriate statistical graphics and choropleth mapping technique.

### Analytical Mapping

-   Plot functional regions delineated by using both non-spatially constrained and spatially constrained clustering algorithms.

## Overview

The process of creating regions is called [regionalisation](https://www.researchgate.net/publication/28153673_Supervised_Regionalization_Methods_A_Survey/link/0fcfd5094046b13d35000000/download). A regionalisation is a special kind of clustering where the objective is to group observations which are similar in their statistical attributes, but also in their spatial location.

In this take-home exercise, we are required to regionalise Nigeria by using, but not limited to the following measures:

-   Total number of functional water points

-   Total number of nonfunctional water points

-   Percentage of functional water points

-   Percentage of non-functional water points

-   Percentage of main water point technology (i.e. Hand Pump)

-   Percentage of usage capacity (i.e. \< 1000, \>=1000)

-   Percentage of rural water points

## Installing & Loading R Packages

In the code chunk below, *p_load()* of **pacman** package is used to install and load the following R packages into R environment.

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse,
               plotly, ggdendro, GGally)
```

## The Data

### Aspatial data

For the purpose of this exercise, data from [WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/) will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. We are required to use WPdx+ data set.

### Geospatial data

Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this exercise. The data can be downloaded either from The [Humanitarian Data Exchange](https://data.humdata.org/) portal or [geoBoundaries](https://www.geoboundaries.org/).

### Importing water point data

First, we are going to import the water point data into R environment.

```{r}
#| eval: false
wp_nga <- read_csv("rawdata/WPdx.csv") %>%
  filter(`#clean_country_name` == "Nigeria")
```

Thing to note from the code chunk above:

-   The original file name is called `Water_Point_Data_Exchange_-_PlusWPdx.csv`, it has been rename to `WPdx.csv` for easy encoding.

-   Instead of using *read.csv()* of Base R to import the csv file into R, *read_csv()* is **readr** package is used. This is because during the initial data exploration, we notice that there is at least one field name with space between the field name (ie. *New Georeferenced Column*).

-   The data file contains water point data of many countries. In this study, we are interested on water point in Nigeria. Hence, *filter()* of **dplyr** is used to extract out records belonging to Nigeria only.

Next, *write_rds()* of **readr** package is used to save the extracted data table (i.e. `wp_nga`) into an output file in rds data format. The output file is called `wpdx_nga.rds` and it is saved in rawdata sub-folder, which will not be uploaded to Git.

```{r}
#| eval: false
wpdx_nga <- write_rds(wp_nga, 
                    "rawdata/wpdx_nga.rds")
```

```{r}
wpdx_nga <- read_rds("rawdata/wpdx_nga.rds")
```

#### Convert wkt data

After the data are imported into R environment, it is a good practice to review both the data structure and the data table if it is in tibble data frame format in R Studio.

```{r}
wpdx_nga
```

Notice that the newly imported tibble data frame (i.e. `wpdx_nga`) contains a field called `New Georeferenced Column` which represent spatial data in a textual format. In fact, this kind of text file is popularly known as **Well Known Text** in short **wkt**.

Two steps will be used to convert an asptial data file in wkt format into a sf data frame by using **sf**. First, *st_as_sfc()* of **sf** package is used to derive a new field called `Geometry` as shown in the code chunk below.

```{r}
wpdx_nga$Geometry = st_as_sfc(wpdx_nga$`New Georeferenced Column`)
```

If we check the `wpdx_nga` data frame and scroll to the last field now, we will see a new field called `Geometry` has been added.

Next, *st_sf()* will be used to convert the tibble data frame into sf data frame.

```{r}
wpdx_sf <- st_sf(wpdx_nga, crs=4326) 
```

The code chunk below reveals the complete information of a feature object by using [*head()*](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/head) of Base R.

```{r}
head(wpdx_sf, n=5)
```

### Importing Nigeria LGA level boundary data

For the purpose of this exercise, shapefile downloaded from [geoBoundaries](https://www.geoboundaries.org/) portal will be used.

```{r}
nga <- st_read(dsn = "data",
               layer = "geoBoundaries-NGA-ADM2",
               crs = 4326) %>%
  select(shapeName)
```

### Correcting duplicated LGAs

The code chunk below (as suggested by [Jordan](https://jordan-isss624-geospatial.netlify.app/posts/geo/geospatial_exercise/#data-wrangling)) uses *duplicated()* of base R which has managed to identify 12 LGAs (ie `shapeName`) having duplicates.

```{r}
nga <- (nga[order(nga$shapeName), ])

nga_dup <- nga$shapeName[nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]

nga_dup
```

After some research, the corrected index and shapeName should be as follows:

| Index | shapeName      |
|-------|----------------|
| 94    | Bassa Kogi     |
| 95    | Bassa Plateau  |
| 304   | Ifelodun Kwara |
| 305   | Ifelodun Osun  |
| 355   | Irepodun Kwara |
| 356   | Irepodun Osun  |
| 519   | Nasarawa Kano  |
| 520   | Nasarawa       |
| 546   | Obi Benue      |
| 547   | Obi Nasarawa   |
| 693   | Surulere Lagos |
| 694   | Surulere Oyo   |

The code chunk below is used to correct the respective `shapeName` values.

```{r}
nga$shapeName[c(94,95,304,305,355,356,519,520,546,547,693,694)] <- 
  c("Bassa Kogi","Bassa Plateau","Ifelodun Kwara","Ifelodun Osun",
    "Irepodun Kwara","Irepodun Osun","Nassarawa Kano","Nassarawa",
    "Obi Benue","Obi Nasarawa","Surulere Lagos","Surulere Oyo")
```

The code chunk below uses *length()* of base R to validate that there are no more duplicates in LGAs.

```{r}
length((nga$shapeName[ nga$shapeName %in% nga$shapeName[duplicated(nga$shapeName)] ]))
```

## Point in Polygon Overlay

Although `wpdx_sf` sf data frame consists of a field called `#clean_adm2` which by right should provide the LGA names of the water points located. However, it is always a good practice to be more cautious when dealing with data accuracy.

In this section, we are going to use a geoprocessing function (or commonly know as GIS analysis) called **point-in-polygon overlay** to transfer the attribute information in `nga` sf data frame into `wpdx_sf` data frame. The code chunk below uses *st_join()* of **sf** package to perform a join and a new field called `shapeName` is now added to `wpdx_sf` sf data frame.

```{r}
wpdx_sf <- st_join(wpdx_sf, nga)
```

## Data Wrangling

### Recoding NA values into string

In the code chunk below, *replace_na()* is used to recode all the *NA* values in `#status_clean` and `#water_tech_category` fields into *Unknown*.

```{r}
wpdx_sf <- wpdx_sf %>%
  mutate(`#status_clean` = replace_na(`#status_clean`, "Unknown")) %>%
  mutate(`#water_tech_category` = replace_na(`#water_tech_category`, "Unknown"))
```

### Extracting useful data points

In the code chunk below, *filter()* of **dplyr** is used to select water points of various `#status_clean`.

```{r}
func_wp <- wpdx_sf %>%
  filter(`#status_clean` %in%
           c("Functional",
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r}
nonfunc_wp <- wpdx_sf %>%
  filter(`#status_clean` %in%
           c("Abandoned/Decommissioned",
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r}
unknown_wp <- wpdx_sf %>%
  filter(`#status_clean` == "Unknown")
```

In the code chunk below, we will check the proportions in `#water-tech-category` and then use *filter()* of **dplyr** to select only the water points of sizable proportions.

```{r}
data_1 <- wpdx_sf %>%
  group_by(`#water_tech_category`) %>%
  summarise(count = n())

ggplot(data_1, aes(x = "", y = count, fill = `#water_tech_category`)) +
  geom_col(color = "black") +
  geom_label(aes(label = count),
             color = "white",
             position = position_stack(vjust = 0.5),
             show.legend = FALSE) +
  coord_polar(theta = "y")
```

```{r}
handpump_wp <- wpdx_sf %>%
  filter(`#water_tech_category` == "Hand Pump")

mechanized_wp <- wpdx_sf %>%
  filter(`#water_tech_category` == "Mechanized Pump")
```

In the code chunk below, *filter()* of **dplyr** is used to select water points of `usage_capacity` \>=1000 and those \<1000.

```{r}
highusage_wp <- wpdx_sf %>%
  filter(usage_capacity >= 1000)

lowusage_wp <- wpdx_sf %>%
  filter(usage_capacity < 1000)
```

In the code chunk below, *filter()* of **dplyr** is used to select water points of `is_urban` = False and those = True.

```{r}
rural_wp <- wpdx_sf %>%
  filter(is_urban == FALSE)

urban_wp <- wpdx_sf %>%
  filter(is_urban  == TRUE)
```

### Performing Point-in-Polygon Count

The code chunk below performs two operations at one go. Firstly, identify water points located inside each LGA by using [*st_intersects()*](https://r-spatial.github.io/sf/reference/geos_binary_pred.html). Next, [*length()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/length) of Base R is used to calculate numbers of water points that fall inside each LGA.

```{r}
nga_wp <- nga %>% 
  mutate(total_wp = lengths(
    st_intersects(nga, wpdx_sf))) %>%
  mutate(func_wp = lengths(
    st_intersects(nga, func_wp))) %>%
  mutate(nonfunc_wp = lengths(
    st_intersects(nga, nonfunc_wp))) %>%
  mutate(unknown_wp = lengths(
    st_intersects(nga, unknown_wp))) %>%
  mutate(handpump_wp = lengths(
    st_intersects(nga, handpump_wp))) %>%
  mutate(mechanized_wp = lengths(
    st_intersects(nga, mechanized_wp))) %>%
  mutate(highusage_wp = lengths(
    st_intersects(nga, highusage_wp))) %>%
  mutate(lowusage_wp = lengths(
    st_intersects(nga, lowusage_wp))) %>%
  mutate(rural_wp = lengths(
    st_intersects(nga, rural_wp))) %>%
  mutate(urban_wp = lengths(
    st_intersects(nga, urban_wp)))
```

The code chunk below reveal the summary statistics of `nga_wp` data frame.

```{r}
summary(nga_wp)
```

### Derive new variables using **dplyr** package

The unit of measurement of the values are number of water points. Using these values directly will be biased towards the underlying total number of water points. In order to overcome this problem, we will derive the percentages of each variable by using the code chunk below.

```{r}
nga_wp_derived <- nga_wp %>%
  mutate(func_perc = func_wp/total_wp) %>%
  mutate(nonfunc_perc = nonfunc_wp/total_wp) %>%
  mutate(handpump_perc = handpump_wp/total_wp) %>%
  mutate(mechanized_perc = mechanized_wp/total_wp) %>%
  mutate(highusage_perc = highusage_wp/total_wp) %>%
  mutate(lowusage_perc = lowusage_wp/total_wp) %>%
  mutate(rural_perc = rural_wp/total_wp) %>%
  mutate(urban_perc = urban_wp/total_wp) %>% 
  select(1:2, 4:5, 13:20)

```

We notice there are some NA values in the `nga_wp_derived` data frame. As such, *is.na()* of base R is used to replace NA with 0.

```{r}
nga_wp_derived[is.na(nga_wp_derived)] = 0
```

Let us review the summary statistics of the newly derived variables using the code chunk below.

```{r}
summary(nga_wp_derived)
```

## Exploratory Data Analysis (EDA)

### EDA using statistical graphics

The code below uses [*ggarange()*](https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html) function of [**ggpubr**](https://rpkgs.datanovia.com/ggpubr/) package to compute multiple histograms so as to reveal the distribution of the selected variables in the `nga_wp_derived` data frame.

```{r}
func_wp <- ggplot(data=nga_wp_derived, 
             aes(x= func_wp)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

nonfunc_wp <- ggplot(data=nga_wp_derived, 
             aes(x= nonfunc_wp)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

func_perc <- ggplot(data=nga_wp_derived, 
             aes(x= func_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

nonfunc_perc <- ggplot(data=nga_wp_derived, 
             aes(x= nonfunc_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

handpump_perc <- ggplot(data=nga_wp_derived, 
             aes(x= handpump_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mechanized_perc <- ggplot(data=nga_wp_derived, 
             aes(x= mechanized_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

highusage_perc <- ggplot(data=nga_wp_derived, 
             aes(x= highusage_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

lowusage_perc <- ggplot(data=nga_wp_derived, 
             aes(x= lowusage_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

rural_perc <- ggplot(data=nga_wp_derived, 
             aes(x= rural_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

urban_perc <- ggplot(data=nga_wp_derived, 
             aes(x= urban_perc)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

```{r}
ggarrange(func_wp, nonfunc_wp, func_perc, nonfunc_perc, handpump_perc,
          mechanized_perc, highusage_perc, lowusage_perc, rural_perc, urban_perc,
          ncol = 4, 
          nrow = 3)
```

From the above, we can observe that `func_perc` and `nonfunc_perc` are more normally distributed compared to other variables.

### EDA using choropleth map

To have a quick look at the distribution of functional water points percentage of Nigeria at LGA level, a choropleth map will be prepared.

The code chunk below is used to prepare the choropleth by using the *qtm()* function of **tmap** package.

```{r}
qtm(nga_wp_derived, "func_perc")
```

In order to reveal the distribution shown in the choropleth map above are biased towards the underlying number of functional water points at the LGAs, we will create two choropleth maps, one for the number of functional water points (i.e. `func.map`) and one for the percentage of functional water points (f`unc_perc.map`) by using the code chunk below.

```{r}
func.map <- tm_shape(nga_wp_derived) + 
  tm_fill(col = "func_wp",
          n = 5,
          style = "jenks", 
          title = "func_wp") + 
  tm_borders(alpha = 0.5) +
  tm_layout(scale = 0.7)

func_perc.map <- tm_shape(nga_wp_derived) + 
  tm_fill(col = "func_perc",
          n = 5,
          style = "jenks",
          title = "func_perc ") + 
  tm_borders(alpha = 0.5) +
  tm_layout(scale = 0.7)

tmap_arrange(func.map, func_perc.map,
             asp=NA, ncol=2)
```

Notice that there are areas with high proportions of functional water points but the actual number of functional water points are low.

## Correlation Analysis

Before we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated. The code below uses [*corrplot.mixed()*](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) function of [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) package to visualise and analyse the correlation of the input variables.

```{r}
nga_wp_derived_new <- nga_wp_derived %>%
  st_set_geometry(NULL)
  
cluster_vars.cor = cor(nga_wp_derived_new[, 2:11])
corrplot.mixed(cluster_vars.cor,
               lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

The correlation plot above shows that `mechanised_perc` and `highusage_perc` are highly correlated, and similar high correlation is also spotted in `handpump_perc` and `lowusage_perc`. This suggests that only one of them in each pair should be used in the cluster analysis instead of both.

## Conventional Hierarchy Cluster Analysis

### Extracting clustering variables

The code chunk below will be used to extract the clustering variables from `nga_wp_derived_new`.

```{r}
cluster_vars <- nga_wp_derived_new %>%
  select("shapeName", "func_wp", "nonfunc_wp","func_perc", "nonfunc_perc", "handpump_perc", "mechanized_perc", "rural_perc", "urban_perc")
head(cluster_vars, 10)
```

Notice that the final clustering variables list does not include variable `highusage_perc` and `lowusage_perc`because they are highly correlated with variable `mechanised_perc` and `handpump_perc` respectively.

Next, we need to change the rows by LGA name instead of row number by using the code chunk below.

```{r}
row.names(cluster_vars) <- cluster_vars$"shapeName"

nga_wp_var <- select(cluster_vars, c(2:9))
head(nga_wp_var, 10)

```

### Data Standardisation

In order to avoid cluster analysis result being biased towards clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.

The code chunk below uses *normalize()* of [*heatmaply*](https://cran.r-project.org/web/packages/heatmaply/) package to standardise the clustering variables.

```{r}
nga_wp_var.std <- normalize(nga_wp_var)
summary(nga_wp_var.std)
```

Note that the values range of the standardised clustering variables are 0-1 now.

### Computing proximity matrix

The code chunk below is used to compute the proximity matrix using *euclidean* method.

```{r}
proxmat <- dist(nga_wp_var.std, method = 'euclidean')
```

The code chunk below can then be used to list the content of `proxmat` for visual inspection.

```{r}
#| eval: false
proxmat
```

![](images/paste-6DB314C7.png)

### Computing hierarchical clustering

The code chunk below uses [*hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html) of R stats to performs hierarchical cluster analysis via the *ward.D* method. The hierarchical clustering output is stored in an object of class **hclust** which describes the tree produced by the clustering process.

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

We can then plot the tree by using [*ggdendrogram()*](https://www.rdocumentation.org/packages/ggdendro/versions/0.1.23/topics/ggdendrogram) of **ggdendro** package as shown in the code chunk below. **Plotly** has also been used here to add interactivity to the dendrogram so that we are able to zoom in and out easily.

```{r}
p <- ggdendrogram(hclust_ward, rotate = FALSE, size = 0.1)

ggplotly(p) %>%
  partial_bundle()
```

### Selecting the optimal clustering algorithm

The code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(nga_wp_var.std, method = x)$ac
}

map_dbl(m, ac)
```

With reference to the output above, we can see that Ward's method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used.

### Determining Optimal Clusters

We will use the Gap Statistic Method to determine the optimal clusters to retain. To compute the gap statistic, [*clusGap()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/clusGap) of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package will be used.

```{r}
set.seed(12345)
gap_stat <- clusGap(nga_wp_var.std, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

Next, we can visualise the plot by using [*fviz_gap_stat()*](https://rpkgs.datanovia.com/factoextra/reference/fviz_nbclust.html) of [**factoextra**](https://rpkgs.datanovia.com/factoextra/) package.

```{r}
fviz_gap_stat(gap_stat)
```

From the output above, the optimal number of clusters is 4.

### Interpreting the dendrograms

The code below uses [*rect.hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/rect.hclust.html) of R stats to add border colors for the rectangles.

```{r}
plot(hclust_ward, cex = 0.1)
rect.hclust(hclust_ward, 
            k = 4, 
            border = 2:5)
```

### Visually-driven hierarchical clustering analysis

The code chunk below uses the [*heatmaply()*](https://talgalili.github.io/heatmaply/reference/heatmaply.html) of [**heatmaply**](https://talgalili.github.io/heatmaply/) package to build an interactive cluster heatmap.

```{r}
nga_wp_var_mat <- data.matrix(nga_wp_var.std)
```

```{r}
heatmaply(normalize(nga_wp_var_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 4,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of LGAs by Cluster Variables",
          xlab = "Cluster Variables",
          ylab = "LGAs of Nigeria"
          )
```

### Mapping the clusters formed

In order to visualise the clusters formed, the code chunk below uses *qtm()* of **tmap** package to plot the choropleth map.

```{r}
groups <- as.factor(cutree(hclust_ward, k=4))
```

```{r}
nga_wp_cluster <- cbind(nga, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
qtm(nga_wp_cluster, "CLUSTER")
```

The choropleth map above reveals that the clusters are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.

## Spatially Constrained Clustering: SKATER approach

### Computing Neighbour List

The code chunk below uses [*poly2nd()*](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package to compute the neighbours list from polygon list.

```{r}
nga_wp_sp <- as_Spatial(nga_wp_derived)

```

```{r}
nga_wp.nb <- poly2nb(nga_wp_sp)
summary(nga_wp.nb)
```

```{r}
plot(nga_wp_sp, 
     border=grey(.5))
plot(nga_wp.nb, 
     coordinates(nga_wp_sp), 
     col="blue", 
     add=TRUE)
```

### Computing minimum spanning tree

#### Recomputing Neighbour List

The neighbours list is recomputed as we remove the LGA with no link.

```{r}
nga_wp_v2 <- nga_wp_derived[c(1:85, 87:774),]
nga_wp_sp_v2 <- as_Spatial(nga_wp_v2)

nga_wp_var_v2 <- nga_wp_var.std[c(1:85, 87:774),]
```

```{r}
nga_wp.nb <- poly2nb(nga_wp_sp_v2)
summary(nga_wp.nb)
```

#### Calculating edge costs

The code chunk below uses [*nbcosts()*](https://r-spatial.github.io/spdep/reference/nbcosts.html) of **spdep** package to compute the cost of each edge, which is the distance between nodes.

```{r}
lcosts <- nbcosts(nga_wp.nb, nga_wp_var_v2)
```

```{r}
nga_wp.w <- nb2listw(nga_wp.nb, 
                   lcosts, 
                   style="B")
summary(nga_wp.w)
```

#### Computing minimum spanning tree

The minimum spanning tree is computed by mean of the [*mstree()*](https://r-spatial.github.io/spdep/reference/mstree.html) of **spdep** package as shown in the code chunk below.

```{r}
nga_wp.mst <- mstree(nga_wp.w)
```

```{r}
class(nga_wp.mst)
```

```{r}
dim(nga_wp.mst)
```

```{r}
head(nga_wp.mst)
```

The plot method for the MST includes a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the LGA boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.

```{r}
plot(nga_wp_sp_v2, border=gray(.5))
plot.mst(nga_wp.mst, 
         coordinates(nga_wp_sp_v2), 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```

### Computing spatially constrained clusters using SKATER method

The code chunk below computes the spatially constrained cluster using [*skater()*](https://r-spatial.github.io/spdep/reference/skater.html) of **spdep** package. The number of cuts used here is 3 as it is 1 less than the number of clusters.

```{r}
clust4 <- spdep::skater(edges = nga_wp.mst[,1:2], 
                 data = nga_wp_var_v2, 
                 method = "euclidean", 
                 ncuts = 3)
```

```{r}
str(clust4)
```

```{r}
ccs4 <- clust4$groups
ccs4
```

```{r}
table(ccs4)
```

We can now plot the pruned tree that shows the 4 clusters on top of the LGA area.

```{r}
plot(nga_wp_sp_v2, border=gray(.5))
plot(clust4, 
     coordinates(nga_wp_sp_v2), 
     cex.lab=.7,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

### Visualising the clusters in choropleth map

The code chunk below is used to plot the newly derived clusters by using SKATER method.

```{r}
groups_mat <- as.matrix(clust4$groups)
nga_wp_sf_spatialcluster <- cbind(nga_wp_v2, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(nga_wp_sf_spatialcluster, "SP_CLUSTER")
```

## Spatially Constrained Hierarchical Clustering

Before we can perform spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using [*st_distance()*](https://r-spatial.github.io/sf/reference/geos_measures.html) of **sf** package.

```{r}
dist <- st_distance(nga_wp_derived, nga_wp_derived)
distmat <- as.dist(dist)
```

Next, *choicealpha()* will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=4, graph = TRUE)
```

With reference to the graphs above, alpha = 0.4 will be used as shown in the code chunk below.

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.4)
```

```{r}
groups <- as.factor(cutree(clustG, k=4))
```

```{r}
nga_wp_sf_Gcluster <- cbind(nga_wp_derived, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

We can now plot the map of the newly delineated spatially constrained clusters.

```{r}
qtm(nga_wp_sf_Gcluster, "CLUSTER")
```

## Visual Interpretation of Clusters

### Visualising individual clustering variable

The code chunk below is used to reveal the distribution of a clustering variable (i.e `func_perc`) by cluster.

```{r}
ggplot(data = nga_wp_sf_Gcluster,
       aes(x = CLUSTER, y = func_perc)) +
  geom_boxplot()
```

The boxplot reveals Cluster 2 displays the highest mean percentage of functional water points. This is followed by Cluster 1, 3 and 4.

### Multivariate Visualisation

The code chunk below uses [*ggparcoord()*](https://ggobi.github.io/ggally/reference/ggparcoord.html) of [**GGally**](https://ggobi.github.io/ggally/) package to display a parallel coordinate plot that can be used to reveal clustering variables by cluster very effectively.

```{r}
ggparcoord(data = nga_wp_sf_Gcluster, 
           columns = c(4:11), 
           scale = "globalminmax",
           alphaLines = 0.1,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of Variables by Cluster",
           groupColumn = "CLUSTER") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_color_viridis(option = "C", discrete=TRUE)
```

From the above, we can infer that Cluster 2 consists of LGAs which are mostly in rural areas having functional water points which are characterised by hand pump technology and low usage capacity. This may suggest this Cluster consists of LGAs which are mainly specialised in farming.
